{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assumed-hollow",
   "metadata": {},
   "source": [
    "# UCL Python Data Working Group February 2021\n",
    "## Basic Jupyter Notebook Use Walkthrough\n",
    "## 1. Introduction to Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-cooler",
   "metadata": {},
   "source": [
    "### UCL Computer Science Postgraduate Admissions Example Walkthrough\n",
    "\n",
    "<img align=\"right\" width=\"200\" height=\"200\" src=\"https://sammcilroy.github.io/images/cop.jpg?raw=true#right\">\n",
    "\n",
    "Jupyter is an development environment for working interactively with Python (and other languages) and is used heavily in data analysis work. It allows you to combine working Python code with text, images and visualisations making it ideal for exploratory data analysis and report writing/sharing. The combination of code and readable text also make Jupyter a useful tool for documentation of processes. We will use synthesized UCL admissions data to walk through the basic functionality of notebooks including data imports, cleaning and manipulaton, basic analysis and visualisation.\n",
    "\n",
    "Code is run in individual 'cells' like this one. You can insert and rearrange cells in any order, run them individually or all at once. \n",
    "\n",
    "Double click on this cell to inspect it. You can see markdown/HTML text being used to create the titles, text and images in this cell. For more info on markdown a useful resource is https://www.markdowntutorial.com\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-swift",
   "metadata": {},
   "source": [
    "## 2. Setup, Python Libraries\n",
    "\n",
    "The first code cell in most Jupyter files will be expected to be your imported libraries or any other general setup for your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import folium\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-queue",
   "metadata": {},
   "source": [
    "## 3 Working with Data, The Pandas Library\n",
    "\n",
    "The Pandas python library is one of the most common tools for working with dataset in python. It allows for importing of data from various text formats, from databases/SQL queries and from APIs. Data can be manipulated, cleaned and analysed replicating the function of SQL or any typical spreadsheet software which you may be using in your own non-python processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-perth",
   "metadata": {},
   "source": [
    "## 3.1 Importing Data\n",
    "\n",
    "We'll use the Pandas library to import data from CSVs containing synthesized UCL Portico (Student Records) Data on Admissions and Offers Made. The data is limited to random courses from Computer Science and Finance to simplify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stadard Python comments are also useful when \n",
    "a markdown cell would be overkill/cumbersome\n",
    "'''\n",
    "# Importing the data...\n",
    "\n",
    "admissions = pd.read_csv('ucl_cs_pg_admissions_synthesized.csv')\n",
    "course_codes = pd.read_csv('ucl_course_codes.csv')\n",
    "cod_codes = pd.read_csv('ucl_country_of_domicile_codes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-lodging",
   "metadata": {},
   "source": [
    "## 3.2 Inspecting and Manipulating Data\n",
    "We can continue using Pandas to inspect our data and make any changes/cleaning necessary before moving on with any analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at data, pandas head() shows the first row(s) of a DataFrame\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head() takes integer argument n, default 5, for number of rows to show.\n",
    "# Pass in argument to change number of rows\n",
    "course_codes.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tail() argument shows the last (n) rows of a DataFrame\n",
    "cod_codes.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-czech",
   "metadata": {},
   "source": [
    "Inspecting the admissions data...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with data types\n",
    "\n",
    "'''\n",
    "When importing data into a DataFrame, unless specified Pandas will assume the data type of each column.\n",
    "'''\n",
    "\n",
    "# check the data types of a DataFrame\n",
    "admissions.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We can see that Pandas has interpreted the year and domicile code as integers. The remaining columns\n",
    "have been assigned to 'object' types meaning they have mixed data types. \n",
    "For our analysis we'll want to make sure any codes that could be interpreted as ints are seen as strings\n",
    "and we can make these changes for individual columns\n",
    "'''\n",
    "admissions['STU_CODC'] = admissions['STU_CODC'].astype(str)\n",
    "admissions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The datatypes are now showing as objects (mixed data types). This is expected as strings in\n",
    "Python are variable length arrays of characters. We can force the data to be strings of fixed\n",
    "length but that is not what we want here.\n",
    "\n",
    "We can also specify/force the data types when importing the data which can be a better practice,\n",
    "although can become unweildy with larger datasets...\n",
    "'''\n",
    "admissions = pd.read_csv('ucl_cs_pg_admissions_synthesized.csv', dtype={'CAP_AYRC': 'int64',\n",
    "                                                                       'CAP_CRSC': 'str',\n",
    "                                                                       'STU_GEND': 'str',\n",
    "                                                                       'STU_CODC': 'str',\n",
    "                                                                       'CAP_IDRC': 'str'})\n",
    "\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the shape of a DataSet, rowsxcolumns\n",
    "admissions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-creation",
   "metadata": {},
   "source": [
    "Seeing the shape of the imported data we can note we see we have 12751 applications made with 5 dimensions of data on these:\n",
    "\n",
    "* CAP_AYRC: The year of the application made\n",
    "* CAP_CRSC: The course (code) applied to\n",
    "* STU_GEND: The gender of the applicant\n",
    "* STU_CODC: The country of domicile (code) of the applicant\n",
    "* CAP_IDRC: The offer made to the applicant and their response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at individual columns with indexing, check unique values\n",
    "admissions['CAP_AYRC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions['CAP_CRSC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(admissions['CAP_CRSC'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-labor",
   "metadata": {},
   "source": [
    "We note that the data shows applications over 3 years for 12 courses. We'll continue using Pandas to manipulate/clean this admissions data so it is more useful for analysis and sharing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns, python dictionary\n",
    "\n",
    "'''\n",
    "renaming of columns with python dictionary. In Python, names are typically either set to 'snake_case'\n",
    "or 'Title Case'. Usually snake_case would be best practice for datasets, particualry large ones, meant\n",
    "for further analysis/storage but we'll use Title Case for here to keep the data 'pretty' and\n",
    "meaningful for export/reports. Either is acceptable depending on your use case and preferences.\n",
    "'''\n",
    "\n",
    "admissions.rename(columns={'CAP_AYRC': 'Year',\n",
    "                          'CAP_CRSC': 'Course Code',\n",
    "                          'STU_GEND': 'Gender',\n",
    "                          'STU_CODC': 'Domicile Code',\n",
    "                          'CAP_IDRC': 'Decision Response'}, inplace=True) \n",
    "                                                                         \n",
    "\n",
    "\n",
    "    \n",
    "'''\n",
    "inplace argument: change the data in place, i.e. modify it. Without this argument, default False,\n",
    "the change will be done on a temporary copy\n",
    "'''\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookups/joins \n",
    "'''\n",
    "Python merge function similar to SQL JOIN/Excel LOOKUP.\n",
    "Use the code lookup tables to replace the course and domicile codes with their actual values\n",
    "'''\n",
    "course_codes.rename(columns={\"CRS_CODE\": 'Course Code'}, inplace=True)\n",
    "admissions = pd.merge(admissions, course_codes, on='Course Code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_codes.rename(columns={'COD_CODE': 'Domicile Code'}, inplace=True)\n",
    "admissions = pd.merge(admissions, cod_codes, on='Domicile Code', how='left')\n",
    "\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering columns, typically accomplished by overwriting the data with a new copy with specified columns\n",
    "admissions = admissions[['Year',\n",
    "                        'Course Code',\n",
    "                         'Gender',\n",
    "                        'CRS_NAME',\n",
    "                        'Domicile Code',\n",
    "                        'COD_NAME',\n",
    "                        'Decision Response']]\n",
    "\n",
    "admissions.rename(columns={'CRS_NAME': 'Course Name',\n",
    "                          'COD_NAME': 'Domicile'}, inplace=True)\n",
    "\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unwanted columns\n",
    "admissions.drop('Course Code', 1, inplace=True)\n",
    "admissions.drop('Domicile Code', 1, inplace=True)\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping one value to another\n",
    "gender_map = {'M': 'Male', 'F': 'Female'}\n",
    "admissions['Gender'] = admissions['Gender'].map(gender_map)\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the data\n",
    "admissions.sort_values('Year', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying custom functions\n",
    "\n",
    "'''\n",
    "define our own basic custom function to add meaning to the decision response codes\n",
    "'''\n",
    "\n",
    "def offer_made(decision):\n",
    "    decision = str(decision)\n",
    "    if decision.startswith('C'):\n",
    "        return 'Conditional Offer'\n",
    "    elif decision.startswith('U'):\n",
    "        return 'Unconditional Offer'\n",
    "    elif decision.startswith('R'):\n",
    "        return 'Rejection'\n",
    "    else:\n",
    "        return 'None'\n",
    "    \n",
    "admissions['Decision Response'] = admissions['Decision Response'].apply(offer_made)\n",
    "admissions.rename(columns={'Decision Response': 'Decision'}, inplace=True)\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned data to a new csv\n",
    "admissions.to_csv('admissions_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-personality",
   "metadata": {},
   "source": [
    "## 4. Analysing the Data\n",
    "\n",
    "Once the data is in a cleaned and ready state, we can continue by appying further Pandas/python functions to explore and analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "quick analysis by functions\n",
    "'''\n",
    "def offer(decision):\n",
    "    decision = str(decision)\n",
    "    if 'Conditional' in decision or 'Unconditional' in decision:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "admissions['Offer'] = admissions['Decision'].apply(offer)\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_made = int(admissions['Offer'].sum())\n",
    "offers_made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_made/len(admissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-marking",
   "metadata": {},
   "source": [
    "Applying aggregate/sum function to quickly count offers shows that 2818 offers were given which is an overall acceptace rate of 22.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregating the data. Let's look at Msc Computer Science only\n",
    "# The indexing below shows the data where the rows matching this statement are True\n",
    "cs = admissions[admissions['Course Name'] == 'MSc Computer Science']\n",
    "cs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can visualise this by looking at the series our statment creates\n",
    "array = admissions['Course Name'] == 'MSc Computer Science'\n",
    "array[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_made = int(cs['Offer'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_rate = offers_made/len(cs)\n",
    "acceptance_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-columbus",
   "metadata": {},
   "source": [
    "MSc Computer Science has 534 offers and a similar acceptance rate of 22.3% over its 2389 applications the past 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using HTML in cells\n",
    "\n",
    "'''\n",
    "show our findings clearly with HTML formatting...\n",
    "'''\n",
    "\n",
    "display(HTML(\"<font-size:40px><b>MSc Computer Science</b><div style = 'background-color: black; padding: 30px '>\" +\n",
    "              \"<span style='color: white; font-size:30px;'> Applications: \"  + str(len(cs)) +\"</span><p>\" +\n",
    "             \"</p><span style='color: white; font-size:30px;'> Offers: \"  + str(offers_made) +\"</span><p>\" +\n",
    "             \"</p><span style='color: green; font-size:30px;'> Acceptance: \" + str(round(acceptance_rate*100,1))+'%' + \"</span>\"+\n",
    "             \"</div>\")\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aggreating/Grouping/Pivoting\n",
    "\n",
    "Pivot and pivot table functionality in Jupyter to quickly report on data and\n",
    "see useful patterns. Can be useful in replicating and automating a lot of the\n",
    "work we see being done in Excel pivot tables...\n",
    "\n",
    "Let's break down the 534 offers made for MSc Computer Science by Year\n",
    "'''\n",
    "cs_offers = cs.groupby(['Year']).sum()\n",
    "cs_offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a pivot table of all admissions data, by year, course and count of offers made by Gender\n",
    "'''\n",
    "offers_made_by_year_by_gender = pd.pivot_table(admissions, values='Offer', index=['Year', 'Course Name'], columns=['Gender'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_made_by_year_by_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We can then continue working with the data with various options, such as sorting, until we have a table\n",
    "we are happy with. Let's sort the table to find the courses recruting the most female applicants each year\n",
    "'''\n",
    "female_offers = offers_made_by_year_by_gender.reset_index().sort_values(['Year', 'Female'], ascending=[0,0]).set_index(['Year', 'Course Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_offers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-parish",
   "metadata": {},
   "source": [
    "The sorted tablenow shows the courses by year sorted by most Female offers made..."
   ]
  },
  {
   "cell_type": "raw",
   "id": "robust-patient",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-nutrition",
   "metadata": {},
   "source": [
    "## 4. Simple Visualisation\n",
    "\n",
    "Looking at Python plots and visulatisations, let's drill down into the MSc Computer Science Offers...\n",
    "\n",
    "### 4.1 Basic Python Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Basic Chart/Plot\n",
    "\n",
    "Show the number of total offers by year. Simple Bar Chart. There are many chart 'kinds' to experiment with\n",
    "in your own reports.\n",
    "'''\n",
    "cs_offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_offers.plot(kind='bar') # Show Msc Computer Science Offers by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_offers.plot(kind='pie', subplots=True) # Show Msc Computer Science Offers by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-islam",
   "metadata": {},
   "source": [
    "### 4.2 Interactive Charts: Plotly Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe sorting by largest sum of Offers, restrict to top 10, sort descending\n",
    "top10_domicile = pd.DataFrame(cs.groupby('Domicile')['Offer'].sum().nlargest(10).sort_values(ascending = False))\n",
    "top10_domicile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plotly Scatterplot, with hover and colour coding by Domicile\n",
    "'''\n",
    "\n",
    "fig1 = px.scatter(top10_domicile, x = top10_domicile.index, y = 'Offer', size = 'Offer', size_max = 120,\n",
    "                color = top10_domicile.index, title = 'MSc Computer Science: Top 10 Domiciles by Offers Made')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-marketing",
   "metadata": {},
   "source": [
    "Looking at all of the admissions data for 2020..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Count the applications made in 2020 by course, and sort \n",
    "'''\n",
    "top10_popular_courses_2020 = pd.DataFrame(admissions[admissions['Year'] == 2020].groupby(['Course Name'])['Course Name'].count().sort_values(ascending = True))\n",
    "top10_popular_courses_2020.rename(columns={'Course Name': 'Applications'}, inplace=True)\n",
    "top10_popular_courses_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plotly Bar Chart with Hover and Heatmap (Colour scale by count of applications)\n",
    "'''\n",
    "\n",
    "top_10_courses_bar = px.bar(top10_popular_courses_2020, x = 'Applications', y = top10_popular_courses_2020.index, height = 600, color = 'Applications', orientation = 'h',\n",
    "            color_continuous_scale = ['skyblue','orange'], title = 'Top 10 Most Applications by Course 2020')\n",
    "top_10_courses_bar.update_layout(barmode='stack', xaxis={'categoryorder':'total ascending'})\n",
    "top_10_courses_bar.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-coach",
   "metadata": {},
   "source": [
    "## 5 Contact\n",
    "\n",
    "While this walkthrough only scratches the surface of the kinds of data processing, analysis and visualisations that can be accomplished we hope this will serve as a jumping off point and template for anyone looking at their own end to end analysis projects or thinking about using Python and/or Jupyter in any aspects of work at UCL. If you have any questions going forward or want to share your own data work then please contact us at the Python Data Working Group:\n",
    "\n",
    "Sam McIlroy: samuel.mcilroy@ucl.ac.uk<p>\n",
    "Si Ning Yeoh: s.yeoh@ucl.ac.uk<p>\n",
    "Oj Akhigbe: oj.akhigbe@ucl.ac.uk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
